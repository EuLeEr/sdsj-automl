![](https://github.com/alxmamaev/image-storage/blob/master/sdsj2018/Снимок%20экрана%202018-11-04%20в%2017.17.38.png)
# Sberbank AutoML solution

## Предобработка датасета

* Если датасет большой _(>2GB)_, тогда мы строим матрицу корреляций и убираем скоррелированные фичи
* Если же датасет маленький, то мы можем позволить себе сделать *Mean Target Encoding* и *One Hot Encoding* для скоррелированных признаков.
* Далее с помощью линейной модели _(Ridge/LogisticRegression)_ выбираем топ-10 признаков с максимальными коэффициентами
* Из этих десяти признаков генерим новые с помощью попарного деления. Таким образом получаем дополнительные 90 фичей _(10^2-10)_


## Обучение модели

* Если датасет маленький, то мы можем позволить себе обучить несколько LightGBM на трех фолдах, после чего усреднить с помощью *ModelsEnsemble*
* Если датасет большой, а времени мало (5 минут), то просто обучаем линейную регрессию
* Иначе учим один бустинг на 800 деревьев


## UDP
_Только сейчас понял, что забыл брать коэффициенты регрессии по модулю_
**¯\\_(ツ)_/¯**

 ## Результаты
_Скоро узнаем что вышло_
